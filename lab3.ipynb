{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferit-osirv/lab1/blob/main/lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vtuqXEBP1j"
      },
      "source": [
        "# Lab 3 - Thresholding and Binary Morphology\n",
        "\n",
        "These laboratory excersises are solved on Google Colab and are save on GitHub repo that is connected to GitHub Classroom.\n",
        "\n",
        "## Tools You need to use to Submit Assignments\n",
        "\n",
        "In this document, you will solve tasks. This is a Jupyter Notebook which has the **.ipynb** extension, is an interactive web environment for data analysis, visualization, solution presentations, education, and more.\n",
        "\n",
        "**Google Colab** is a tool that allows you to run and share Jupyter Notebook files on Google's servers, including the use of Google's CPU, GPU, and TPU resources. Colab is like Google Docs for Jupyter Notebooks. **Google Colab does not automatically save your assignment to GitHub.**\n",
        "\n",
        "**You use GitHub to save and submit your assignments.** When you accept the assignment through GitHub Classroom, a repository is automatically created on your GitHub account with a copy of the task. This is where you will save your solutions. Saving your solutions submits the tasks for that lab.\n",
        "\n",
        "## How to Solve the Tasks?\n",
        "1. Accept the task via the Google Classroom link that you will receive. Google Classroom will create a repository on your account.\n",
        "2. Go to the newly created repository on your account and click on the .ipynb file, then click Open in Colab.\n",
        "3. You will solve the tasks in Google Colab.\n",
        "\n",
        "## How to Save (Submit) Tasks?\n",
        "\n",
        "1. In Google Colab, click on the Open settings gear icon in the top-right corner.\n",
        "2. Click on the GitHub tab and check the box for Access private repositories and organizations.\n",
        "3. A new window will open for you to grant access to GitHub. For ferit-osirv, click Grant.\n",
        "4. Save and exit the settings.\n",
        "5. Click on File > Save a copy in GitHub.\n",
        "6. Select the lab repository that includes your name.\n",
        "\n",
        "> *Note:* You only need to complete steps 1-4 the first time.\n",
        "\n",
        "7. Click on **File > Save a copy in GitHub**.\n",
        "8. Select created repository **koji uključuje vaše ime**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUPz7IDCbDx"
      },
      "source": [
        "## Copying Files from a GitHub Repository\n",
        "\n",
        "To complete the exercises, you will need images and other files that are located in the GitHub repository of the exercise. This command will be available in the notebook for each exercise. It will copy files from GitHub to the Google Colab environment.\n",
        "\n",
        "**You need to run this command before starting each exercise.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpP_i0KgCefb",
        "outputId": "e08a0979-cb3c-41f4-be61-07957597ae31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'clone'...\n",
            "remote: Repository not found.\n",
            "fatal: repository 'https://github.com/ferit-osirv/lab2/' not found\n"
          ]
        }
      ],
      "source": [
        "!rm -rf clone && git clone https://github.com/ferit-osirv/lab2 clone && cp -a clone/. ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIPg8Vf9Cr8D"
      },
      "source": [
        "**Google Colab will occasionally delete all files.** Therefore, it may be necessary to rerun this command between sessions. If you are getting errors about missing files, try running the above command again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EXS_YJC2WsWD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Thresholding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Thresholding?\n",
        "\n",
        "The simplest segmentation method\n",
        "\n",
        "Application example: Separate out regions of an image corresponding to\n",
        "objects which we want to analyze. This separation is based on the variation\n",
        "of intensity between the object pixels and the background pixels.\n",
        "\n",
        "To differentiate the pixels we are interested in from the rest (which will\n",
        "eventually be rejected), we perform a comparison of each pixel intensity\n",
        "value with respect to a threshold (determined according to the problem to\n",
        "solve).\n",
        "\n",
        "Once we have separated properly the important pixels, we can set them with\n",
        "a determined value to identify them (i.e. we can assign them a value of 0\n",
        "(black), 255 (white) or any value that suits your needs).\n",
        "\n",
        "![](https://docs.opencv.org/2.4/_images/Threshold_Tutorial_Theory_Example.jpg)\n",
        "\n",
        "\n",
        "## Simple Thresholding\n",
        "\n",
        "Here, the matter is straight forward. If pixel value is greater than a\n",
        "threshold value, it is assigned one value (may be white), else it is assigned\n",
        "another value (may be black). The function used is `cv2.threshold`. First\n",
        "argument is the source image, which should be a grayscale image. Second\n",
        "argument is the threshold value which is used to classify the pixel values.\n",
        "Third argument is the ` maxVal ` which represents the value to be given if pixel\n",
        "value is more than (sometimes less than) the threshold value. OpenCV provides\n",
        "different styles of thresholding and it is decided by the fourth parameter of\n",
        "the function. Different types are:\n",
        "\n",
        "- cv2.THRESH_BINARY\n",
        "- cv2.THRESH_BINARY_INV\n",
        "- cv2.THRESH_TRUNC\n",
        "- cv2.THRESH_TOZERO\n",
        "- cv2.THRESH_TOZERO_INV\n",
        "\n",
        "To illustrate how these thresholding processes work, let’s consider that we\n",
        "have a source image with pixels with intensity values $` src(x,y) `$. \n",
        "The plot below\n",
        "depicts this. The horizontal blue line represents the threshold $` thresh `$ (fixed).\n",
        "\n",
        "![](https://docs.opencv.org/2.4/_images/Threshold_Tutorial_Theory_Base_Figure.png)\n",
        "\n",
        "The documentation clearly explains what each type is meant for. [Please check out the\n",
        "documentation](http://docs.opencv.org/doc/tutorials/imgproc/threshold/threshold.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3\n",
        "\n",
        "Using OpenCV, load the image `images/apple.jpg` as a **grayscale** image. Perform simple **binary** thresholding in two ways: 1) using the OpenCV function mentioned above, and 2) using NumPy by setting all pixels above a certain value to 255 and others to 0. Display the thresholded image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ### Otsu Binarization\n",
        "\n",
        "**Binarization** of an image is the process of converting the image into a format where each pixel can only be one of two possible values. For `uint8` images, these values are usually `0` (black) and `255` (white). For `float` images, the values are `0` (black) or `1.0` (white). **Binarization** is often a precursor to **thresholding**, where the image is divided into completely white and black regions, and then only the parts of the original image that are completely white in the binary image are retained. Mathematically, by multiplying the original and binary images, the pixels that are completely white in the binary image remain unchanged, while those that are completely black are multiplied by 0, resulting in a completely black pixel in the product image.\n",
        "\n",
        "In the previous example, you manually determined the threshold. Otsu binarization is a more advanced method that determines the optimal threshold based on the **histogram** of the image, which best separates the pixels. A histogram is a graph that shows the frequency of each value in a data set. In the case of an image, the histogram shows, for each color value, how many pixels are of that color.\n",
        "\n",
        "Let's take a look at the histogram of the `apple.jpg` image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = cv.imread('images/apple.jpg', cv.IMREAD_GRAYSCALE)\n",
        "plt.hist(img.flatten(), bins=256, range=(0, 255))\n",
        "plt.ylim([0, 10000])\n",
        "plt.xlim([0, 255])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the histogram, it is evident that most pixels are grouped around the values 255 and 50. By approximation, we see that the optimal way to separate the pixels into two groups would be with a threshold between 150 and 200, as this threshold effectively separates the two largest groups of pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4\n",
        "\n",
        "According to the following link, implement Otsu binarization for the `apple.jpg` image. Display the resulting binary image **using Matplotlib**. Print the optimal threshold value determined by the Otsu method to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Such a binary image can be used as a **mask** for the original image. A mask is a binary image where the value is `0` for all pixels that should not be visible, and the maximum value (`1.0` or `255`) for pixels that should be visible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5\n",
        "\n",
        "Using the Otsu binary image as a mask, apply the function `img_thresholded = cv.bitwise_and(img, img, mask=mask)` where `img` is the original grayscale image of the apple, and `mask` is the Otsu binary image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Improving Masks with Binary Morphology\n",
        "\n",
        "Morphological operations such as `erosion`, `dilation`, `closing` and `opening` are common tools used to improve masks after they are generated by thresholding. They can be used to fill small holes, remove noise, increase or decrease the size of an object, or smoothen mask outlines.\n",
        "\n",
        "Most morphological operations are once again simple kernel functions that are applied at each pixel of the image based on their neighborhood as defined by a `structuring element (SE)`. For example, `dilation` simply assigns to the central pixel the maximum pixel value within the neighborhood; it is a maximum filter. Conversely, `erosion` is a minimum filter. Additional options emerge from combining the two: `morphological closing`, for example, is a `dilation` followed by an `erosion`. This is used to fill in gaps and holes or smoothing mask outlines without significantly changing the mask's area. Finally, there are also some more complicated morphological operations, such as `hole filling`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPdsk5aJ45he4xMUxx8bkpd",
      "include_colab_link": true,
      "name": "lab1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
